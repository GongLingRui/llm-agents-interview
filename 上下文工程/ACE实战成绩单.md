### ACE “实战成绩单”

**以小博大，成本暴降90%！**

（ACE精讲03）

#### 上期回顾 (理论)

1. G-R-C 三角工作流

2. 三大创新机制


#### 本期内容 (证据)

1. ACE 到底有多强？

2. ACE 为什么这么强？

3. ACE 到底有多快？

### 实验 1 (AppWorld): 核心数据 & 两大发现

#### 核心数据
| 场景   | 方法                | 平均分 | 结论         |
|--------|---------------------|--------|--------------|
| 基线   | ReAct (Base LLM)    | 42.4%  | "裸考"       |
| 离线   | ReAct + ICL (样例)  | 46.0%  | "开卷"       |
| 离线   | ReAct + GEPA (SOTA) | 46.4%  | "离线工厂"   |
| 离线   | ReAct + ACE         | 59.4%  | ACE 胜出     |
| 在线   | ReAct + DC          | 51.9%  | "在线笔记本" |
| 在线   | ReAct + ACE         | 59.5%  | ACE 胜出     |


#### 两大发现
- **发现 1：无需标签的“自进化”**

  结果：就算没有“正确答案”，ACE 依然拿到了57.2%的高分（远超46.4%的GEPA）。

  结论：ACE 仅靠“自然的执行反馈”（如代码报错）就能反思。

- **发现 2：“以小博大” (vs GPT-4.1)**

  ACE (搭载 DeepSeek-V3.1): 59.4%

  IBM CUGA (搭载 GPT-4.1): 60.3%

  结论：ACE 用“开源小模型”匹配(Match)了“闭源大模型”的 SOTA 成绩。


### 实验 2：金融领域
ACE 在“金融分析”(FINER, Formula) 任务上再次全面碾压所有基线 (GEPA, DC)。

| 场景   | 方法          | FINER (Acc↑) | Formula (Acc↑) |
|--------|---------------|--------------|----------------|
| 离线   | GEPA          | 73.5%        | 71.5%          |
| 离线   | ACE (Offline) | 78.3%        | 76.5%          |
| 在线   | DC            | 74.2%        | 69.5%          |
| 在线   | ACE (Online)  | 76.6%        | 76.5%          |


#### 一个诚实的“局限性”

在金融任务上，如果没有“正确答案”作为反馈，ACE (在线) 的性能会下降 (72.9%)。

**原因**：金融任务没有“自然的执行反馈”(不像代码会报错)。如果模型自己都做不对，它就无法“反思”出正确的教训，反而会用“错误的洞见”污染“战术手册”。
  
### 为什么 ACE 这么强？“消融实验”
**证明我们上一期讲的“三大创新”都是必要的**

| 方法 (Ablation)                          | 平均分 (Average) | 结论     |
|------------------------------------------|------------------|----------|
| ACE (完整版)                             | 59.4%            | 完整引擎 |
| ACE w/o multi-epoch (去掉“多轮精炼”)     | 56.8%            | ↓ 2.6%   |
| ACE w/o Reflector... (去掉“反思器”和“多轮精炼”) | 55.1%            | ↓ 4.3%   |


#### 补充结论
1. 去掉“反思器” (Reflector)，性能暴跌 4.3%。
→ 证明“专用反思器”不是摆设，它真的能对抗“简洁性偏见”。

2. 去掉“多轮精炼” (multi-epoch)，性能下降 2.6%。
→ 证明“迭代精炼”是有效的，“战术手册”值得被反复打磨。

### ACE 这么强，一定很贵吧？
**结论：它不仅更强，而且更快、更便宜！**

#### “离线” (Offline) vs GEPA
ACE (编译手册时) …
- → 延迟 (Latency) 降低 82.3%
- → LLM调用 (Rollouts) 减少 75.1%


#### “在线” (Online) vs DC
ACE (实时进化时) …
- → 延迟 (Latency) 降低 91.5%
- → Token 成本 (Cost) 降低 83.6%


#### 为什么这么快？
- **DC**：一次“超级大调用”(整体重写 18k Tokens)
- **ACE**：两次“小调用”(R+C) + 一次“非LLM”的合并

