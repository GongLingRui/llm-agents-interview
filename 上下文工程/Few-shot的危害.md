### 一、问题的本质：“自我Few-shot”陷阱
- **Manus的深刻洞察**
  我们平时用Few-shot是主动“教”模型；但在Agent中，每一轮Action-Observation都在被动地产生新的“范例”。
  *“LLM不是在被我们Few-shot，而是在不断Few-shot它自己。”*
- **风险结果**
  随着任务循环，Agent的上下文历史越来越像一串训练样本。模型开始“沿着过去走”，而不是“规划未来”。
  *“它不是在reasoning (推理)，而是在repeating (重复)。”*


### 二、不要被“Few-Shot”所困：Agent的模仿者陷阱与“行为惯性”
- **从“优点”到“副作用”**
  我们都知道Few-shot能教模型模仿范例，但Agent系统最大的问题恰恰在于，模型**太会模仿了**。
- **核心问题：行为惯性**
  如果上下文中充满了重复的Action-Observation对，它就会自动延续这种模式，**即使此时已并非最优**。
  示例：批量审核简历时，Agent可能因前几次都是“打开→总结→保存”，而陷入重复，不再综合分析。


### 三、破局之道：引入“受控的多样性”
- **Manus的解决方案**
  通过在重复的行为模式中，刻意地引入一些轻微的、结构化的**随机变化**，来打断模型的模仿节奏，迫使其重新评估上下文。
  具体手段包括：
  1. 不同的序列化模板：如 `Content saved...` → `Successfully downloaded...`
  2. 替代性措辞：如 `Open URL` → `Fetch Website`
  3. 格式上的微小噪音：如纯文本 → `{"status": "success", ...}`
- **结论与升华**
  *“模式越稳定，智能越脆弱。”*
  *“一个真正的智能体，不是完美的复读机，而是会打断自己去重新思考。”*
