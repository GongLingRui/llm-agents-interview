https://lucumr.pocoo.org/2025/11/21/agents-are-hard/


# 《Agent Design Is Still Hard》网页总结
本文是Armin Ronacher于2025年11月21日发布的博客文章，聚焦Agent（智能体）构建的难点与实践经验，涵盖SDK选择、缓存管理、强化机制等多个核心维度，核心结论为“构建Agent仍复杂混乱，现有工具 abstractions（抽象）在实际工具使用中易失效，需针对性解决多环节问题”。


## 一、Agent SDK选择：不建议优先用高层抽象SDK
1. **选择困境与反思**：作者团队曾采用Vercel AI SDK的 provider abstractions（提供商抽象）并自行驱动Agent循环，后发现该选择不佳。高层抽象SDK（如Vercel AI SDK）的统一化设计存在局限，例如与Anthropic的网页搜索工具结合时会破坏消息历史，且Anthropic SDK直接使用时缓存管理更便捷、错误提示更清晰。
2. **核心原因**：不同模型差异显著，Agent设计需根据工具特性（缓存控制、强化需求、工具提示等）定制抽象层，而现有高层SDK的抽象无法满足个性化需求，反而限制控制权；直接使用平台原生SDK（如OpenAI SDK、Anthropic SDK）能更灵活地适配Agent构建需求。
3. **开放态度**：作者承认可能存在更优解决方案，欢迎读者通过邮件分享经验。


## 二、缓存管理：偏好显式管理，Anthropic模式更优
1. **平台差异**：各平台缓存策略不同，Anthropic需用户付费且显式管理缓存点，初期看似繁琐，实则更优。
2. **显式缓存的优势**：可实现对话分支并行运行、上下文编辑，成本和缓存利用率更可预测，对Agent成本的把控更精准；而其他平台缓存效果不稳定。
3. **作者团队的缓存实践**：在Anthropic Agent中设置多个缓存点（系统提示后1个、对话开头2个且后者随对话尾部移动），为避免缓存失效，将系统提示和工具选择设为静态，通过后续动态消息提供当前时间等信息，并结合循环中的强化机制优化缓存。


## 三、Agent循环中的强化机制：多场景注入关键信息
1. **强化的核心作用**：工具调用后向循环反馈信息，包括提醒Agent整体目标与任务状态、为工具调用失败提供成功提示、告知后台状态变化（如并行处理中的相关状态）。
2. **具体场景案例**：
   - 自强化工具：Claude Code中的“todo write tool”仅接收并回显Agent的任务列表，即可比“初始上下文设定任务”更有效推动Agent进展。
   - 环境变化告知：当Agent重试时依赖损坏数据，注入消息建议其退回几步重新执行 earlier step（早期步骤）。


## 四、故障隔离：减少失败对Agent循环的干扰
1. **两种隔离方式**：
   - 子Agent独立执行：将需迭代的任务交由子Agent运行，仅向主Agent反馈成功结果及失败方法摘要，帮助主Agent规避同类错误，同时避免失败信息占用主上下文。
   - 上下文编辑（Anthropic支持）：可移除上下文中无利于循环成功的失败信息，节省Token，但目前作者团队实践效果不佳，且会自动失效缓存，需权衡“Token节省”与“缓存失效成本”。
2. **关键原则**：需让Agent了解失败原因，但无需保留所有失败的完整状态和输出。


## 五、子Agent/子推理：依赖文件系统实现数据共享
1. **核心需求**：Agent（尤其是代码执行与生成类）需统一数据存储位置，避免“死胡同”（如工具生成的图像仅能传入特定工具，无法用于其他操作）。
2. **解决方案：虚拟文件系统**：所有工具（如代码执行工具`ExecuteCode`、推理工具`RunInference`）均可访问同一虚拟文件系统，支持数据双向流动（例：代码执行工具解压压缩包后，推理工具读取文件并描述内容，再由代码执行工具继续处理），工具需支持通过文件路径访问该系统。


## 六、输出工具：设计与使用中的挑战
1. **工具定位**：Agent非聊天会话模式，中间消息不对外暴露，需通过输出工具（作者团队用其发送邮件）向用户/外部传递信息，使用时机由提示词指导。
2. **核心问题**：
   - 措辞与语气难把控：相比直接用Agent循环文本输出，输出工具的语气调整更困难，推测与模型训练方式相关。
   - 子模型优化无效：尝试用Gemini 2.5 Flash调整语气，反而增加延迟、降低输出质量，且可能泄露中间步骤信息；增加上下文输入则提升成本且未解决根本问题。
   - 工具调用缺失：部分情况下Agent不触发输出工具，作者团队通过“记录工具调用状态”解决——若循环结束未调用，注入强化消息鼓励使用。


## 七、模型选择：根据任务场景适配，Token成本非唯一标准
1. **主循环模型**：Haiku和Sonnet仍是最佳工具调用模型，透明度高；Gemini模型为备选；GPT系列模型在主循环中表现不佳。
2. **子工具模型**：处理大文档总结、PDF、图像信息提取时，Gemini 2.5更优，因Sonnet系列易触发安全过滤器。
3. **成本考量**：优秀的工具调用模型（如Sonnet）能以更少Token完成任务，虽单模型成本可能高于廉价模型，但在循环中整体成本更优。


## 八、测试与评估（Testing and Evals）：当前最大难题
1. **核心困境**：Agent的智能体特性导致测试难度远超普通提示词——无法在外部系统完成评估，需依赖可观测性数据或实际测试运行的 instrumentation（ instrumentation（插桩））。
2. **现状**：作者团队尝试的所有解决方案均未达预期，该环节已成为Agent构建中日益棘手的问题，亟待突破。


## 九、编码Agent更新：试用Amp，认可其设计理念
1. **试用原因**：Amp并非“客观更优”，但作者认可其设计思路，例如子Agent（如Oracle）与主循环的交互设计出色，且类似Claude Code，体现了“工具开发者自用”的产品属性，有助于验证不同Agent设计的有效性。
2. **行业对比**：作者认为并非所有行业内的Agent都具备“Amp/Claude Code式”的实用设计。


## 十、推荐阅读与观点分享
1. [What if you don’t need MCP at all?]：Mario提出多数MCP服务器过度设计，建议浏览器Agent场景用简单CLI工具（如start、navigate等）通过Bash执行，减少Token占用并提升流程灵活性，作者已基于此构建Claude/Amp Skill。
2. [The fate of “small” open source]：作者认同“小型单用途开源库时代将终结”的观点，因平台原生API和AI工具可按需生成简单工具。
3. [Tmux is love]：无完整文章，核心观点为Tmux功能强大，若Agent需交互系统，建议为其添加Tmux技能。
4. [LLM APIs are a Synchronization Problem]：作者认为该主题篇幅较长，已单独撰写文章。


## 十一、网页附加信息
- 作者：Armin Ronacher，博客包含blog（博客）、archive（存档）、projects（项目）等栏目。
- 版权：2025年Armin Ronacher所有，内容基于知识共享“署名-非商业性使用-相同方式共享”协议授权。
- 联系与订阅：可通过邮件、Bluesky、X（原Twitter）、GitHub联系作者，支持GitHub赞助，提供Atom/RSS订阅方式，网页支持自动/浅色/深色配色切换。
