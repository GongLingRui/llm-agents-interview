https://arxiv.org/pdf/2402.01680

# 《Large Language Model based Multi-Agents: A Survey of Progress and Challenges》总结
## 一、研究背景与动机
1. **LLM单智能体基础**：大型语言模型（LLMs）具备类人推理与规划能力，可作为自主智能体完成感知、决策、行动等任务，在指令理解、复杂交互等场景快速发展。此前已有研究总结LLM单智能体进展，但缺乏对多智能体系统的系统性梳理。
2. **LLM多智能体优势**：基于单智能体的能力延伸，LLM多智能体系统通过两点提升性能：一是将LLMs特化为不同能力的智能体，二是让多样化智能体交互以模拟复杂现实环境，可模拟人类团队协作解决问题，且能利用LLMs的文本通信能力、跨领域知识与任务专精潜力。
3. **研究现状与需求**：LLM多智能体已在软件开发、多机器人系统、社会模拟等领域取得成果，吸引AI、社会科学、心理学等多领域研究者关注，相关论文数量快速增长（如图1所示）。但此前研究分散，缺乏系统性综述，亟需梳理领域框架、总结挑战，因此开展本综述研究。


## 二、LLM多智能体系统核心构成
### 2.1 智能体-环境接口（Agents-Environment Interface）
定义智能体与部署环境的交互方式，分为三类：
| 接口类型 | 定义 | 应用场景示例 |
|----------|------|--------------|
| 沙盒环境（Sandbox） | 人类构建的模拟/虚拟环境，智能体可自由实验行动与策略 | 软件开发（代码解释器为模拟环境）、游戏（基于游戏规则的环境，如狼人杀） |
| 物理环境（Physical） | 现实世界环境，智能体需与物理实体交互并遵循物理规则 | 机器人扫地、制作三明治、整理橱柜等实体任务 |
| 无环境（None） | 无特定外部环境，智能体不与环境交互 | 多智能体辩论达成共识（如科学议题辩论） |

### 2.2 智能体画像（Agents Profiling）
定义智能体的特质、行动与技能，以适配特定目标，包括画像类型与构建方法：
1. **常见画像示例**：游戏中“预言家”“狼人”等角色、软件开发中“产品经理”“工程师”“测试员”、辩论中的“正方”“反方”“评委”。
2. **构建方法**：
   - 预定义（Pre-defined）：由系统设计者明确设定智能体画像。
   - 模型生成（Model-Generated）：通过LLMs等模型自动创建智能体画像。
   - 数据驱动（Data-Derived）：基于已有数据集构建智能体画像。

### 2.3 智能体通信（Agents Communication）
支撑集体智能的核心基础设施，从三方面解析：
1. **通信范式（Paradigms）**：
   - 协作式（Cooperative）：智能体为共同目标合作，交换信息优化集体解决方案。
   - 辩论式（Debate）：智能体提出并捍卫观点、批判他人观点，以达成共识或优化方案。
   - 竞争式（Competitive）：智能体追求自身目标，可能与其他智能体目标冲突。
2. **通信结构（Structure）**（如图3所示）：
   - 分层结构（Layered）：智能体按层级组织，各层级角色明确，主要在层级内或相邻层级交互（如DyLAN框架的多层前馈网络）。
   - 去中心化结构（Decentralized）：基于对等网络，智能体直接交互，常用于世界模拟。
   - 中心化结构（Centralized）：由中心智能体协调通信，其他智能体通过中心节点交互。
   - 共享消息池（Shared Message Pool）：智能体发布/订阅消息（如MetaGPT框架），提升通信效率。
3. **通信内容（Content）**：以文本为主，内容随应用场景变化，如软件开发中交流代码片段、狼人杀游戏中讨论策略与怀疑对象。

### 2.4 智能体能力获取（Agents Capabilities Acquisition）
智能体动态学习与进化的关键过程，包括反馈类型与能力调整策略：
1. **反馈类型**：
   - 环境反馈：来自现实/虚拟环境（如软件开发中代码解释器的反馈、机器人从物理环境获取的反馈）。
   - 智能体交互反馈：来自其他智能体的判断或交互（如科学辩论中通过交流优化结论、游戏中基于交互调整策略）。
   - 人类反馈：直接来自人类，用于对齐多智能体系统与人类价值观（如“人类在环”应用）。
   - 无反馈：部分世界模拟场景（如传播模拟）仅关注结果分析，无需反馈。
2. **能力调整策略**：
   - 记忆（Memory）：智能体存储历史交互与反馈信息，行动时检索相关有效记忆（如成功经验）优化当前行为。
   - 自我进化（Self-Evolution）：智能体动态调整自身（如修改目标、优化策略、基于交互日志微调LLMs），如ProAgent框架通过通信日志调整策略、LTC范式利用交互数据训练模型。
   - 动态生成（Dynamic Generation）：系统运行中实时生成新智能体以适配需求（如应对突发任务挑战）。


## 三、LLM多智能体应用场景
分为“问题解决”与“世界模拟”两大类，具体场景及核心特征如下表（节选关键场景）：

| 应用大类 | 具体场景 | 代表研究 | 智能体-环境接口 | 核心通信/能力特征 |
|----------|----------|----------|------------------|-------------------|
| 问题解决 | 软件开发 | [Hong et al., 2023]、[Qian et al., 2023] | 沙盒 | 协作式通信、分层/共享消息池结构；通过记忆+自我进化调整能力 |
|          | 多机器人协作 | [Mandi et al., 2023]、[Zhang et al., 2023c] | 沙盒/物理 | 协作式通信、中心化/去中心化结构；依赖记忆调整行为 |
|          | 科学实验 | [Zheng et al., 2023] | 物理 | 协作式通信、中心化结构；结合人类反馈与记忆优化实验流程 |
|          | 科学辩论 | [Du et al., 2023]、[Xiong et al., 2023] | 无 | 辩论式通信、中心化/去中心化结构；通过智能体交互反馈与记忆提升推理准确性 |
| 世界模拟 | 社会模拟 | [Park et al., 2023]（25人社区）、[Park et al., 2022]（1000人社区） | 沙盒/无 | 无固定通信结构；通过记忆/动态生成模拟社会行为与传播 |
|          | 游戏模拟 | [Xu et al., 2023b]（狼人杀）、[Light et al., 2023b]（阿瓦隆） | 沙盒 | 协作+辩论+竞争式通信、去中心化结构；依赖环境与交互反馈调整策略 |
|          | 经济模拟 | [Li et al., 2023e]（宏观经济）、[Li et al., 2023g]（金融交易） | 无/物理 | 协作+辩论式通信、去中心化结构；通过记忆优化经济决策 |
|          | 政策模拟 | [Xiao et al., 2023]（水污染危机）、[Hua et al., 2023]（战争模拟） | 无 | 协作/竞争式通信、去中心化结构；利用记忆模拟政策影响 |
|          | 疾病传播模拟 | [Williams et al., 2023]、[Ghaffarzadegan et al., 2023] | 沙盒 | 协作式通信、去中心化结构；通过记忆模拟人类防疫行为 |


## 四、实现工具与资源
### 4.1 开源多智能体框架
| 框架名称 | 核心特点 | 应用侧重 |
|----------|----------|----------|
| MetaGPT | 嵌入人类工作流，将标准操作流程（SOP）编码到系统，采用流水线式角色分配 | 降低复杂任务中的幻觉问题，适用于软件开发等需要结构化协作的场景 |
| CAMEL（Communicative Agent Framework） | 基于“初始提示”（inception prompting）引导智能体自主协作，可生成对话数据 | 研究智能体交互行为，适用于需要自主协作的通用任务 |
| AutoGen | 高度可定制，支持用自然语言与代码定义智能体交互逻辑 | 跨领域应用，如编码、数学、娱乐等 |

### 4.2 数据集与基准（Table 2节选）
| 应用场景 | 数据集/基准 | 用途 | 数据链接状态 |
|----------|--------------|------|--------------|
| 软件开发 | HumanEval、MBPP、SoftwareDev | 评估多智能体代码生成与协作能力 | 可获取 |
| 多机器人协作 | RoCoBench、C-WAH、TDW-MAT | 评估机器人协作规划与执行能力 | 可获取 |
| 科学辩论 | MMLU、MedQA、PubMedQA、GSM8K | 评估推理与事实准确性 | 可获取 |
| 游戏模拟 | Werewolf、Avalon、Welfare Diplomacy | 评估游戏策略与多智能体交互能力 | 部分无链接 |
| 心理学模拟 | Ultimatum Game TE、Garden Path TE | 模拟人类心理行为与决策 | 可获取 |

注：科学实验操作、经济分析等领域仍缺乏全面基准，需进一步开发。


## 五、挑战与未来机遇
### 5.1 核心挑战
1. **多模态环境适配**：当前LLM多智能体主要聚焦文本环境，缺乏处理图像、音频、物理动作等多模态数据的能力，需解决多模态数据处理与跨模态交互问题。
2. **幻觉问题治理**：单智能体幻觉在多智能体系统中会产生“级联效应”（一个智能体的错误信息被其他智能体传播），需同时在个体与系统层面检测和缓解幻觉。
3. **集体智能获取**：现有系统依赖即时反馈（如环境/人类反馈）学习，缺乏可靠交互环境设计；且多通过个体记忆/自我进化调整，未充分利用智能体网络的协同效应。
4. **系统扩展性**：智能体数量增加会导致计算资源需求激增（如基于GPT-4的智能体），同时需解决大规模智能体的协调、通信效率与缩放定律问题（如智能体编排Agents Orchestration）。
5. **评估与基准缺失**：现有评估多关注单个智能体的窄场景能力，忽视多智能体的涌现行为；科学实验、疾病传播等领域缺乏全面基准。

### 5.2 未来机遇
1. **跨领域应用拓展**：在金融、教育、医疗、城市规划等领域探索LLM多智能体的复杂问题解决能力。
2. **理论视角融合**：结合认知科学、符号AI、控制论、复杂系统等理论，深化对多智能体系统的理解。
3. **技术迭代方向**：开发多模态多智能体技术、抗幻觉机制、高效智能体编排算法，完善领域基准数据集。


## 六、总结
本综述系统梳理了LLM多智能体系统的核心构成（智能体-环境接口、画像、通信、能力获取）、应用场景（问题解决与世界模拟）、工具资源，并指出当前挑战与未来方向。研究团队还维护了开源GitHub仓库（https://github.com/taichengguo/LLM MultiAgents Survey Papers），实时更新领域最新研究，为跨学科研究者提供参考，推动LLM多智能体的理论与应用创新。
