https://link.springer.com/content/pdf/10.1007/s11704-024-40231-1.pdf

# 《A survey on large language model based autonomous agents》PDF总结
## 一、研究背景与意义
1. **传统自主智能体局限**：传统自主智能体研究多在孤立环境中训练，依赖有限知识与启发式策略函数，与人类学习过程差异显著，难以实现类人决策，尤其在无约束、开放域场景中表现不佳。
2. **大语言模型（LLMs）的突破**：LLMs通过海量网络知识学习，展现出类人智能潜力，为构建自主智能体提供新方向。基于LLMs的自主智能体无需特定领域数据训练即可拥有全面内部世界知识，还能通过自然语言界面与人类交互，具备灵活性与可解释性。
3. **研究必要性**：当前已有众多基于LLMs的自主智能体模型，但缺乏全面、整体的总结与对比。本研究对该快速发展领域进行系统综述，有助于研究者全面理解领域现状，为未来研究提供启发。

## 二、基于LLMs的自主智能体构建
### （一）智能体架构设计
提出包含四个核心模块的统一架构框架，各模块作用及细节如下：
|模块|核心功能|关键细节|
| ---- | ---- | ---- |
|**画像模块（Profiling Module）**|明确智能体角色，为LLMs行为提供导向|1. **角色信息类型**：涵盖人口统计学信息（年龄、性别等）、心理信息（性格特质）、社交信息（与其他智能体关系），具体选择取决于应用场景。<br>2. **角色生成策略**：<br>- 手工构建法：手动指定角色信息，灵活但大规模应用时耗时费力，如Generative Agent、MetaGPT等。<br>- LLM生成法：基于生成规则和种子示例，由LLMs自动生成角色，节省时间但对生成结果控制精度低，如RecAgent。<br>- 数据集对齐法：从真实世界数据集提取人类信息构建角色，使智能体行为更贴合现实，如基于美国全国选举研究（ANES）数据的角色分配。|
|**记忆模块（Memory Module）**|存储环境感知信息，辅助智能体积累经验、自我进化|1. **记忆结构**：<br>- 统一记忆：仅模拟人类短期记忆，通过上下文学习实现，信息直接写入提示词，易实现但受LLMs上下文窗口限制，如RLP、SayPlan等。<br>- 混合记忆：同时模拟短期和长期记忆，短期记忆缓存近期感知，长期记忆通过向量数据库等存储重要信息，提升长程推理能力，如Generative Agent、AgentSims等。<br>2. **记忆格式**：包括自然语言（灵活易懂，保留丰富语义）、嵌入向量（提升检索效率）、数据库（便于高效操作）、结构化列表（简洁传递语义），且多种格式可结合使用。<br>3. **记忆操作**：<br>- 记忆读取：依据时效性、相关性、重要性评分提取有用信息，评分函数可通过参数调整侧重不同维度。<br>- 记忆写入：解决记忆重复（如合并相似成功行动序列）和记忆溢出（如按用户指令删除、FIFO覆盖）问题。<br>- 记忆反思：模拟人类自我认知，总结抽象高阶信息，可基于已有洞察分层生成，如Generative Agent、GITM等。|
|**规划模块（Planning Module）**|将复杂任务分解为子任务，指导智能体合理行动|1. **无反馈规划**：<br>- 单路径推理：任务分解为级联步骤，LLMs按步骤执行，如Chain of Thought（CoT）、Zero-shot-CoT等。<br>- 多路径推理：推理步骤呈树状结构，存在多种选择，如Self-consistent CoT（CoT-SC）、Tree of Thoughts（ToT）等。<br>- 外部规划器：借助专业外部工具生成领域特定规划，如LLM+P将任务转换为PDDL语言后使用外部规划器。<br>2. **有反馈规划**：结合环境、人类或模型反馈迭代调整规划，适用于复杂长程任务，如ReAct结合“思考-行动-观察”三元组、Inner Monologue收集多类型反馈等。|
|**行动模块（Action Module）**|将智能体决策转化为具体输出，与环境直接交互|1. **行动目标**：包括完成任务（如游戏中制作工具、软件开发）、沟通协作（与人类或其他智能体交流）、环境探索（拓展感知范围）。<br>2. **行动生成**：<br>- 基于记忆回忆：从记忆中提取相关信息触发行动，如Generative Agent、GITM等。<br>- 基于计划遵循：严格按照预生成计划执行行动，如DEPS、GITM等。<br>3. **行动空间**：<br>- 外部工具：调用API（如HuggingGPT调用HuggingFace模型）、数据库/知识库（如ChatDB用SQL查询）、外部模型（如ViperGPT用Codex生成代码）。<br>- 内部知识：依赖LLMs自身的规划、对话、常识理解能力，如DEPS、ChatDev等。<br>4. **行动影响**：改变环境状态、更新智能体内部状态、触发新行动。|

### （二）智能体能力获取
根据是否微调LLMs分为两类策略：
1. **需微调的能力获取**：基于任务相关数据集微调LLMs，数据集来源包括：
   - 人类标注数据集：由人工标注构建，适用多种场景，如CoH基于人类反馈的自然语言数据集微调、EduChat基于教育场景标注数据微调。
   - LLM生成数据集：由LLMs完成标注，成本低、规模大，如ToolBench用ChatGPT生成API相关指令微调LLaMA。
   - 真实世界数据集：直接使用现实数据，如MIND2WEB基于多领域网站数据微调提升Web任务能力。
2. **无需微调的能力获取**：
   - 提示工程：通过设计优质提示词激发LLMs能力，如CoT提供推理步骤示例、Retroformer将失败反思融入提示词。
   - 机制工程：设计专用模块或规则提升能力，包括试错（如RAH、DEPS）、众包（如多智能体辩论达成共识）、经验积累（如GITM、Voyager）、自驱动进化（如LMA3、SALLM-MS）。

## 三、基于LLMs的自主智能体应用
### （一）社会科学领域
1. **心理学**：用于模拟实验（如LLMs模拟人类参与心理学实验，存在“超精确扭曲”现象）、心理健康支持（如缓解用户焦虑但可能生成有害内容）。
2. **政治与经济学**：检测意识形态、预测投票模式，分析政治演讲结构，模拟经济行为。
3. **社会模拟**：构建虚拟环境模拟社会现象，如信息传播、人类日常生活，如Social Simulacra、Generative Agent等。
4. **法学**：辅助法律决策，如Blind Judgement模拟法官决策、ChatLaw优化法律信息检索并减少幻觉。
5. **研究助手**：辅助文献总结、关键词提取、研究脚本撰写，挖掘新研究问题。

### （二）自然科学领域
1. **文献与数据管理**：高效查询信息、提取文献关键内容、预测物质结构性质，如ChatMOF、ChemCrow。
2. **实验助手**：自动设计、规划和执行实验，提供实验建议并提示安全风险，如基于LLMs的实验自动化系统、ChemCrow。
3. **自然科学教育**：开发教育工具，辅助数学问题解决与讲解、编程教学、作文批改，如Math Agents、CodeHelp、EduChat等。

### （三）工程领域
1. **土木工程**：辅助复杂结构设计与优化，实现人机协作设计，如3D模拟环境中的交互设计框架。
2. **计算机科学与软件工程**：自动化编码、测试、调试、文档生成，如ChatDev、MetaGPT、ToolBench等，还可检测代码漏洞、辅助数据库异常诊断。
3. **工业自动化**：结合数字孪生实现生产过程智能规划与控制，应用于石油天然气等行业，如GPT4IA、IELLM。
4. **机器人与具身智能**：提升机器人规划、推理与协作能力，设计个性化服务机器人，如SayCan、TidyBot等。

此外，还涌现出多个开源库，如LangChain、AutoGPT、AgentVerse等，方便开发者快速实现和评估智能体。

## 四、基于LLMs的自主智能体评估
### （一）主观评估
1. **人类标注**：人类 evaluators 对智能体输出评分或排序，评估维度包括无害性、诚实性、有用性等，但成本高、效率低且存在群体偏差。
2. **图灵测试**：判断智能体输出与人类输出的差异，若无法区分则说明智能体具备类人性能，如EmotionBench比较LLMs与人类的情绪表达。
3. **LLMs辅助评估**：用LLMs替代人类进行主观评估，如ChemCrow用GPT评估实验结果、ChatEval通过多智能体辩论评估。

### （二）客观评估
1. **评估指标**：
   - 任务成功指标：成功 rate、奖励/分数、覆盖率、准确率等。
   - 类人相似度指标：轨迹/位置准确率、对话相似度、人类响应模仿度等。
   - 效率指标：规划长度、开发成本、推理速度、澄清对话次数等。
2. **评估协议**：
   - 真实世界模拟：在游戏、模拟器等环境中评估智能体实际能力。
   - 社会评估：基于智能体在模拟社会中的交互评估社交智能。
   - 多任务评估：通过多领域任务评估智能体泛化能力。
   - 软件测试：评估智能体在测试用例生成、漏洞修复等任务中的表现。
3. **评估基准**：包括游戏环境（如Minecraft）、综合评估框架（如AgentBench、SocKET）、特定领域基准（如WebShop、PEB）等。

## 五、挑战与未来方向
1. **角色扮演能力**：LLMs对Web上少见或新兴角色模拟效果差，且难以准确建模人类认知心理特征，需探索更优微调数据与提示/架构设计。
2. **广义人类对齐**：传统LLMs对齐统一人类价值观，而模拟场景需智能体展现多样价值观（包括负面），需研究“重新对齐”策略。
3. **提示鲁棒性**：智能体包含多模块，提示框架复杂且易受微小改动影响，缺乏跨LLMs的统一稳健提示框架。
4. **幻觉问题**：LLMs易生成虚假信息，可能导致严重后果，需加强人类反馈校正等缓解措施。
5. **知识边界**：LLMs训练数据远超人类个体知识，模拟时需约束其使用未知知识，确保模拟真实性。
6. **效率问题**：LLMs自回归架构推理速度慢，智能体多次查询LLMs影响行动效率。

## 六、结论
本综述从构建、应用、评估三个维度系统总结基于LLMs的自主智能体研究，梳理技术分类与发展历程，指出当前挑战，为领域新人提供全面背景知识，为后续突破性研究提供方向。
