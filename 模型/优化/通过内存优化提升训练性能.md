https://medium.com/data-science/how-to-increase-training-performance-through-memory-optimization-1000d30351c8

# 网页总结：通过内存优化提升训练性能
## 一、核心目标
文章聚焦于深度学习模型训练中GPU（及其他训练加速器，如TPU、Habana Gaudi）的内存利用率优化，旨在**不改变模型架构和收敛能力**的前提下，减少内存消耗，进而实现增大批处理大小、提升训练吞吐量等目标，同时适用于大模型训练与普通模型训练场景。

## 二、内存优化的重要性
1. **支持大模型训练**：许多数十亿参数的大型深度学习模型无法单GPU容纳，需通过内存优化结合模型分布策略（如多GPU协同）实现训练，相关库（deepspeed、fairscale、GSPMD等）均依赖内存优化技术。
2. **增大批处理大小**：批处理大小受GPU可用内存限制，优化内存可释放空间以提升批处理大小。对使用对比损失（需大量正负样本）的模型而言，大批次大小至关重要，且通常能提升训练吞吐量（因单次训练步骤存在固定成本，如GPU内核加载、梯度共享，批次越大单位样本成本越低）。
3. **提升GPU性能**：GPU处理内存量越小，所需计算资源越少；同时优化内存可改善内存对齐，减少内存填充浪费（如未遵循Google Cloud TPU性能指南可能导致大量计算资源浪费），进而提升吞吐量。


## 三、关键内存优化技术
### （一）混合精度训练（Mixed Precision）
1. **原理**：默认训练用32位浮点数（float32），混合精度训练结合16位浮点数（float16或bfloat16），可减半浮点张量内存占用；bfloat16因更适配机器学习场景为优选，但仅支持较新硬件。部分操作仍需保留float32以保证精度或性能。
2. **实现（PyTorch）**：通过`torch.cuda.amp.autocast`接口指定精度（如bfloat16），使用float16时需额外梯度缩放步骤，代码示例如下：
```python
for idx, (inputs, target) in enumerate(data_loader, start=1):
    inputs = inputs.to(torch.cuda.current_device())
    targets = torch.squeeze(target.to(torch.cuda.current_device()), -1)
    optimizer.zero_grad()
    with torch.cuda.amp.autocast(dtype=torch.bfloat16):
        outputs = model(inputs)
        loss = loss_function(outputs, targets)
    loss.backward()
    optimizer.step()
```
3. **效果**：适度增大批处理大小，显著提升训练速度。


### （二）激活检查点（Activation Checkpointing）
1. **原理**：标准训练中前向传播会存储所有中间激活张量用于反向传播；激活检查点仅存储指定激活张量输出，其余激活张量通过存储的检查点重新计算，以**重复部分前向计算**为代价减少内存占用。
2. **实现（PyTorch）**：通过`torch.utils.checkpoint.checkpoint`封装模型层（如timm的VisionTransformer的Block），代码示例如下：
```python
def build_model():
    model_args ={
            "img_size": 224, "patch_size": 14, "embed_dim": 2560,
            "mlp_ratio": 4.0, "num_heads": 16, "depth": 16
        }
    from timm.models.vision_transformer import Block
    import torch.nn as nn
    from torch.utils.checkpoint import checkpoint
    class CKPTBlock(nn.Module):
        def __init__(self, dim, num_heads, mlp_ratio=4., ...):
            super().__init__()
            self.block = Block(dim, num_heads, mlp_ratio, ...)
        def forward(self, x):
            return checkpoint(self.block, x)
    model_args['block_fn'] = CKPTBlock
    return VisionTransformer(**model_args)
```
3. **注意事项**：可能影响依赖随机变量的层（如dropout）和收集统计信息的层（如batch normalization），需提前评估处理；可能增加单步训练时间，但可通过增大批处理大小提升整体吞吐量。


### （三）零冗余优化器（ZeRO）——以ZeRO3为例
1. **原理**：替代标准数据并行方案（如PyTorch的DDP），将模型参数分片存储在多GPU上（N个GPU各存1/N模型），减少参数冗余；GPU计算时临时从对应GPU获取所需参数，计算后立即释放，梯度更新后仅需将结果传递给参数所属GPU。
2. **特点**：内存节省与GPU数量成线性关系，仅适用于多GPU场景；需增加约50%的GPU间网络通信。
3. **实现**：
    - 现有实现：deepspeed、fairscale；PyTorch 1.11及以上版本提供官方实现`FullyShardedDataParallel`（FSDP）。
    - 代码示例（PyTorch FSDP，支持混合精度与激活检查点）：
```python
def wrap_model(model, local_rank):
    from functools import partial
    from timm.models.vision_transformer import Block
    from torch.distributed.fsdp import FSDP, MixedPrecision, ShardingStrategy
    from torch.distributed.fsdp.wrap import transformer_auto_wrap_policy
    # 混合精度配置
    mixed_prec = True
    bfSixteen = MixedPrecision(param_dtype=torch.bfloat16, reduce_dtype=torch.bfloat16, buffer_dtype=torch.bfloat16)
    mp_policy = bfSixteen if mixed_prec else None
    # 自动封装策略
    my_auto_wrap_policy = partial(transformer_auto_wrap_policy, transformer_layer_cls={Block,})
    # FSDP封装模型
    model = FSDP(model, auto_wrap_policy=my_auto_wrap_policy, mixed_precision=mp_policy, device_id=torch.cuda.current_device(), sharding_strategy=ShardingStrategy.FULL_SHARD)
    # 激活检查点（需PyTorch nightly版本）
    ckpt_act = True
    if ckpt_act:
        from torch.distributed.algorithms._checkpoint.checkpoint_wrapper import checkpoint_wrapper, CheckpointImpl, apply_activation_checkpointing_wrapper
        check_fn = lambda submodule: isinstance(submodule, Block)
        non_reentrant_wrapper = partial(checkpoint_wrapper, offload_to_cpu=False, checkpoint_impl=CheckpointImpl.NO_REENTRANT)
        apply_activation_checkpointing_wrapper(model, checkpoint_wrapper_fn=non_reentrant_wrapper, check_fn=check_fn)
    return model
```
4. **相关技术**：ZeRO3是模型分片技术的一种，其他还包括流水线并行（模型分片为连续片段，各片段在单独GPU运行）、张量并行（特定层/张量在多GPU间分片）。


## 四、实验验证
### （一）GPU实验（Amazon EC2 p4.24xlarge，8 GPU，PyTorch）
1. **目标**：验证不同优化技术对批处理大小和训练速度（每秒样本数）的影响。
2. **关键结果**：
    - 混合精度：批处理大小适度增加，训练速度显著提升。
    - 激活检查点：批处理大小大幅增加，但训练速度略有下降。
    - FSDP+混合精度：实现最大训练吞吐量。
    - 三种技术结合：实现最大批处理大小。
3. **注意事项**：PyTorch中最大化内存利用率可能导致内存分配失败与重试（后台进行，无用户通知），可能降低吞吐量，需参考官方教程排查。


### （二）TPU实验（Cloud TPUv3–8 VM）
1. **PyTorch/XLA实验**：
    - 特点：需依赖`torch-xla`库，支持16位浮点数但不支持自动混合精度（需手动配置），PyTorch 1.12及以上支持FSDP，API与PyTorch FSDP不同。
    - 结果：bfloat16既增大批处理大小又提升吞吐量；ZeRO3与激活检查点进一步增大批处理大小，对吞吐量影响中等。
2. **TensorFlow内存对齐实验**：
    - 问题：TPU会将通道数或批处理大小填充为128的倍数，未优化时（如通道数64、批处理大小64）存在2倍填充开销，浪费近40%计算资源。
    - 优化方案：混合精度减少内存占用，可将批处理大小提升至128，填充开销降低，训练吞吐量提升3倍以上。


## 五、总结
1. 内存优化是深度学习训练资源高效利用的关键，核心技术包括混合精度训练、激活检查点、ZeRO3（FSDP）等，可实现批处理大小增大与训练吞吐量提升。
2. 不同技术各有优劣，需根据硬件（GPU/TPU）、框架（PyTorch/TensorFlow）、模型需求选择，必要时结合多种技术；实验结果因项目细节差异较大，需自行详细评估。
3. 相关技术不仅适用于大模型训练，普通模型训练中掌握这些技术也能带来显著收益。
